# Search-Engine
## Abstract
This article discusses the step-by-step process of developing a rudimentary information retrieval system capable of indexing and searching a limited set of documents. A broad system architecture is described, as well as the reasoning behind particular choices made during the construction of the various components. The initial component of the system was document analysis and pre-processing, which required cleaning and translating the raw text of the documents into an indexable and searchable format. The indexing construction component entailed creating an index of the pre-processed documents and putting them in a suitable data structure. The third component was search and ranking, which comprised finding and ranking materials that matched a particular query. The system was examined using the Cranfield collection, and while it achieved acceptable performance, there was still space for improvement. Future system enhancements might include the use of more sophisticated indexing and retrieval techniques, as well as the incorporation of a feedback mechanism to improve the ranking algorithm over time.
â€ƒ
## Introduction
The goal of this project was to create a basic information retrieval system that could index a small collection of documents, conduct queries on them, and return a ranked list of documents. The system design was divided into three parts: document analysis and pre-processing, indexing building, and search and ranking. This study discusses the critical procedures and decisions taken in the construction of these components.

## Document Analysis and Pre-Processing
The initial component of the system was document analysis and pre-processing. This entailed cleaning and translating the raw text of the papers into a searchable and indexable format. To pre-process the papers, a mix of approaches including as tokenization, stemming, and stop-word removal were applied.
The NLTK library was used to tokenize the text, which included breaking it down into individual words or tokens. The tokens were then stemmed to reduce them to their underlying word forms. the way that the way that the way that the way that the way that the way that it was.
Stop-word elimination entailed deleting common terms such as "the," "a," "an," "in," and others that have little significance and are useless for searching using the NLTK library's stop word list.
To maintain text uniformity, techniques such as case-folding and character normalization were applied. To consider different cases of a word as the same, case-folding required changing all of the text to lowercase or uppercase. 

## Indexing Construction
The second component of the system was indexing construction. This entailed creating an index of the pre-processed documents and saving it in a suitable data structure. Each phrase was mapped to a list of documents using an inverted index data structure. This enabled for the easy retrieval of papers containing a certain phrase.
Apart from the term-document mapping, additional information was saved, such as the frequency of each term in each document, the total number of terms in each document, and the length of each document. Weighting the terms in the index was accomplished using techniques such as term frequency-inverse document frequency (TF-IDF) This assigned higher weights to terms that were rare in the collection but occurred frequently in a particular document, indicating that they were more important for that document. 

Techniques such as positional indexing were also used to store information about the position of each term in the document. This allowed for phrase queries, where documents that contained a specific phrase could be searched for.

## Search and Ranking
The search and ranking component of the system involved retrieving documents that matched a given query and ranking them based on their relevance. Three different ranking models were implemented in this step: the Vector Space Model, BM25, and the Language Model.
The Vector Space Model is a popular model for document ranking that uses term frequency-inverse document frequency (TF-IDF) weights. To find the most similar documents, the documents and query were represented as vectors, and the cosine similarity was calculated.
 
The BM25 retrieval model is a probabilistic retrieval model that considers the length of the document as well as the frequency of the term in the collection. It is a popular model in information retrieval, and it has been shown to perform well on a variety of datasets.
 
The Language Model is a probabilistic model that estimates the probability of a document given a query. It is based on the assumption that the terms in a document are generated by a language model, and that the query is a sample from that same model. The likelihood of the document given the query is then calculated using this model.
 
## Evaluation
The Cranfield collection was used to assess the system, which consisted of a modest amount of documents and questions. The documents and queries were pre-processed using the same methods as previously indicated. The Mean Average Precision (MAP), Precision at 5 (P@5), and Normalized Discounted Cumulative Gain (NDCG) scores were calculated using Trec eval, a commonly used tool for assessing information retrieval systems.
The results were analyzed, stressing the strengths and flaws of the system. One of the benefits of the system was its ability to handle phrase inquiries and get documents that included the correct phrase. This was due to the use of positional indexing and the vector space model. 
However, one of the system's flaws was the lack of query expansion techniques that took the context of the query into consideration. This could lead to a lower recall of the system, as important documents that did not contain exact query terms could be missed. Another weakness was the lack of a precise feedback mechanism that allowed users to provide feedback on the results and improve the ranking algorithm over time.

## Conclusion
Finally, a rudimentary information retrieval system that could index a small collection of documents, conduct queries on them, and create an output in the form of a ranked list of documents was successfully developed. The method performed well on the Cranfield collection, but there was still potential for improvement. The project's key findings were presented, and prospective system additions and enhancements were proposed.
Potential expansions include the use of more complex indexing and retrieval techniques such as Latent Semantic Indexing (LSI) and Probabilistic Retrieval Models. Another enhancement was the inclusion of a precise feedback feature, which allowed users to submit input on the results and help the ranking algorithm improve over time.
